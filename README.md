# DataEngineering-AzureDatabricks_Spark

## Building a solution architecture for a data engineering solution using Azure Databricks, Azure Data Lake Gen2, Azure Data Factory and Power BI

1. Creating and using Azure Databricks service and the architecture of Databricks within Azure.
2. Creating DataLake service to read and write data using Azure DataLake Storage Gen2.
3. Performing ETL/ELT activities using PySpark and SparkSQL.
4. Creating, Scheduling and Monitoring pipelines to execute Databricks notebooks using data factory triggers to execute at regular intervals.
5. Creating dashboards to visualise the outputs by connecting to the Azure Databricks tables from PowerBI.

![1626666804120](https://user-images.githubusercontent.com/62457161/127802691-ac161f31-691c-40ac-9243-c48252089f60.jpg)
